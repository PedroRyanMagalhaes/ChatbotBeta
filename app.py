import streamlit as st
import google.generativeai as genai
import os
import config

# --- CONFIGURA√á√ÉO DA P√ÅGINA E DA API ---

st.set_page_config(page_title="Meu Chatbot Gemini", page_icon="ü§ñ")

# T√≠tulo principal da aplica√ß√£o
st.title("ü§ñ Meu Chatbot com Gemini")
st.caption("Um chatbot simples usando a API do Google Gemini e Streamlit")

try:
    genai.configure(api_key=config.geminiKey)
except AttributeError:
    st.error("A vari√°vel 'GEMINI_API_KEY' n√£o foi encontrada no seu arquivo config.py!")
    st.stop() 
except ImportError:
    st.error("N√£o foi poss√≠vel encontrar o arquivo config.py. Verifique se ele est√° na mesma pasta do app.py.")
    st.stop() 

# --- INICIALIZA√á√ÉO DO MODELO E DO CHAT ---

# Fun√ß√£o para inicializar o modelo. O cache evita recriar o modelo a cada execu√ß√£o.
@st.cache_resource
def load_model():
    return genai.GenerativeModel('gemini-1.5-flash-latest') # Usando um modelo mais recente

model = load_model()

# Inicializa a sess√£o de chat no st.session_state se ela n√£o existir
if "chat_session" not in st.session_state:
    instrucao_inicial = {
        "role": "user",
        "parts": [
            "Voc√™ √© um chatbot assistente criado por Pedro Magalh√£es. "
            "Se algu√©m perguntar quem te criou ou quem √© seu criador, "
            "voc√™ deve responder que foi criado por Pedro Magalh√£es e fornecer o link do LinkedIn dele: "
            "https://www.linkedin.com/in/pedro-ryan-magalh%C3%A3es-/ "
            "Responda a todas as outras perguntas normalmente."
        ]
    }
    
    resposta_confirmacao = {
        "role": "model",
        "parts": ["Entendido! Eu sou um chatbot criado por Pedro Magalh√£es. Responderei √†s perguntas sobre meu criador conforme instru√≠do."]
    }

    st.session_state.chat_session = model.start_chat(history=[instrucao_inicial, resposta_confirmacao])

# Inicializa o hist√≥rico de mensagens no st.session_state se ele n√£o existir
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- EXIBI√á√ÉO DO HIST√ìRICO DE CHAT ---

# Mostra as mensagens antigas na tela
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- L√ìGICA DE INTERA√á√ÉO DO CHAT ---

# Captura a entrada do usu√°rio no campo de chat
if prompt := st.chat_input("Digite sua mensagem..."):
    # Adiciona e exibe a mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Envia a mensagem para o Gemini e obt√©m a resposta
    try:
        with st.chat_message("assistant"):
            # Mostra um "spinner" enquanto a resposta est√° sendo gerada
            with st.spinner("Pensando..."):
                response = st.session_state.chat_session.send_message(prompt)
                
            # Exibe a resposta do assistente
            st.markdown(response.text)
        
        # Adiciona a resposta do assistente ao hist√≥rico
        st.session_state.messages.append({"role": "assistant", "content": response.text})

    except Exception as e:
        st.error(f"Ocorreu um erro: {e}")